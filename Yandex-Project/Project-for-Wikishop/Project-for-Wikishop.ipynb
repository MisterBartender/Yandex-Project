{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак.\n",
    "\n",
    "**План работы:**\n",
    "\n",
    "[1  Подготовка](#section1)\n",
    "\n",
    "[2  Обучение](#section2)\n",
    "\n",
    "- [LogisticRegression](#section2.1)\n",
    "\n",
    "- [DecisionTreeClassifier](#section2.2)\n",
    "\n",
    "- [RandomForestClassifier](#section2.3)\n",
    "\n",
    "- [LGBMClassifier](#section2.4)\n",
    "\n",
    "- [XGBClassifier](#section2.5)\n",
    "\n",
    "[3  Вывод](#section3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section1'></a>\n",
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# загружаем необходимые библиотеки\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "plt.style.use('seaborn-pastel')\n",
    "import seaborn as sns \n",
    "import numpy as np \n",
    "\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "pd.options.display.max_columns = None \n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# введём константу\n",
    "RANDOM_STATE = 12345"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим необходимые файлы для английской библиотеки лемматизатора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "stopwords = set(nltk_stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим данные, выведем первые 10 строк"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Your vandalism to the Matt Shirvington article...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Sorry if the word 'nonsense' was offensive to ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>alignment on this subject and which are contra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  toxic\n",
       "0           0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1           1  D'aww! He matches this background colour I'm s...      0\n",
       "2           2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3           3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4           4  You, sir, are my hero. Any chance you remember...      0\n",
       "5           5  \"\\n\\nCongratulations from me as well, use the ...      0\n",
       "6           6       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK      1\n",
       "7           7  Your vandalism to the Matt Shirvington article...      0\n",
       "8           8  Sorry if the word 'nonsense' was offensive to ...      0\n",
       "9           9  alignment on this subject and which are contra...      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/datasets/toxic_comments.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# избавимся от столбца \"Unnamed: 0\" - он не понадобится для дальнейшей работы\n",
    "df = df.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159292 entries, 0 to 159291\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159292 non-null  object\n",
      " 1   toxic   159292 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пропусков нет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    143106\n",
       "1     16186\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# посмотрим соотношение токсичных комментариев к общему числу\n",
    "df['toxic'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Имеется яный дисбаланс"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- От лишних символов текст очистят регулярные выражения. Для работы с регулярными выражениями в Python будем использовать встроенный модуль re. \n",
    "- Создадим функцию, которая очистит текст для будущей лемматизации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_text(text):\n",
    "     # преобразовываем и переводим в нижний регистр\n",
    "    text = re.sub(r'[^a-zA-Z ]', ' ', text.lower())\n",
    "    retext = text.split() \n",
    "    text = \" \".join(retext)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перед извлечением признаков текста необходимо его упростить. \n",
    "Этапами предобработки будет следующее:\n",
    "- разбиение текста на отдельные слова, фразы, символы - токенизация\n",
    "- приведение слова к начальной форме - лемматизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функцию для тоекнизации и лемматизации текста\n",
    "def lemmetize(words):\n",
    "    lemmatizer = WordNetLemmatizer() \n",
    "    text = [] # создаём список для заполнения\n",
    "    tokens = word_tokenize(words) # токенизируем текст\n",
    "    for token in tokens: # лемматизируем каждый токен\n",
    "        lemmetized_word = lemmatizer.lemmatize(token) \n",
    "        text.append(lemmetized_word)\n",
    "    sentence = \" \".join(text) # объединение в текст обратно\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применяем функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         explanation why the edits made under my userna...\n",
       "1         d aww he match this background colour i m seem...\n",
       "2         hey man i m really not trying to edit war it s...\n",
       "3         more i can t make any real suggestion on impro...\n",
       "4         you sir are my hero any chance you remember wh...\n",
       "                                ...                        \n",
       "159287    and for the second time of asking when your vi...\n",
       "159288    you should be ashamed of yourself that is a ho...\n",
       "159289    spitzer umm there no actual article for prosti...\n",
       "159290    and it look like it wa actually you who put on...\n",
       "159291    and i really don t think you understand i came...\n",
       "Name: lemm_text, Length: 159292, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['lemm_text'] = df['text'].apply(clear_text)\n",
    "df['lemm_text'] = df['lemm_text'].apply(lemmetize)\n",
    "\n",
    "df['lemm_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для определения тематики и тональности текста, алгоритм необходимо обучить на корпусе, что является набором текстов, в котором эмоции и ключевые слова уже размечены. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определяем тренировочную и тестовую выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, test_features, train_target, test_target = train_test_split(\n",
    "    df.drop('toxic', axis = 1),\n",
    "    df['toxic'],\n",
    "    test_size = 0.25,\n",
    "    random_state = RANDOM_STATE,\n",
    "     # стратифицируем текст, чтобы выборки были более сбалансированы\n",
    "    stratify = df['toxic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129315    accusation of vandalism what wa the cause and ...\n",
       "8868      shorter oxford english dictionary arrived toda...\n",
       "75827     kim stop you are not helping here this is fann...\n",
       "137701    my blocking by user jayron i believe that this...\n",
       "28407     simple quote don t you think this essentially ...\n",
       "                                ...                        \n",
       "54715     indeed bigdunc that page rightly say that para...\n",
       "85775     it s a criticism moron it doesn t need to be s...\n",
       "71196     forgive my cruddy formattingi m still relative...\n",
       "55751     talk grasshopper scout i moved your comment fr...\n",
       "11543                                  oppose wp commonname\n",
       "Name: lemm_text, Length: 119469, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# вытаскиваем корпусы\n",
    "corpus_train = train_features['lemm_text']\n",
    "corpus_test = test_features['lemm_text']\n",
    "corpus_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Воспользуемся TfidfVectorizer, чтобы почистить мешок слов, добавим в него стоп-слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер матрицы: (119469, 133602)\n",
      "Размер матрицы: (39823, 133602)\n"
     ]
    }
   ],
   "source": [
    "# подгружаем счетчик и задаём стоп-слова\n",
    "count_tf_idf = TfidfVectorizer(stop_words = stopwords)\n",
    "# обучаем и трансформируем\n",
    "tf_idf_train = count_tf_idf.fit_transform(corpus_train) \n",
    "# трансформируем тестовую без обучения\n",
    "tf_idf_test = count_tf_idf.transform(corpus_test) \n",
    "\n",
    "print(\"Размер матрицы:\", tf_idf_train.shape)\n",
    "print(\"Размер матрицы:\", tf_idf_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод:**\n",
    "\n",
    "- Обработка данных выполнена (токенизация, лемматизация)\n",
    "- Тестовую и тренировочную выборки определены для обучения\n",
    "- TF-IDF подсчитано (оценка важности слова)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section2'></a>\n",
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При обучении будут спользованы следующие модели: \n",
    "- LogisticRegression\n",
    "- DecisionTreeClassifier\n",
    "- RandomForestClassifier\n",
    "- LGBMClassifier\n",
    "- XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим функцию, которая обучит и вернёт модель, создаст и заполнит таблицу для дальнейшего анализа получившихся метрик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# таблица для анализа\n",
    "analisys = pd.DataFrame({'model':[], 'F1_model':[], 'F1_on_train':[]})\n",
    "all_models = []\n",
    "\n",
    "# функции для подбора параметров\n",
    "def train_model(model, parameters):\n",
    "    \n",
    "    model_random = RandomizedSearchCV(\n",
    "        estimator = model,\n",
    "        param_distributions = parameters,\n",
    "        scoring = 'f1', \n",
    "        n_jobs = -1,\n",
    "        cv = 4, \n",
    "        verbose = 2\n",
    "    )\n",
    "    \n",
    "    # подсчет скорости вычисления\n",
    "    start = time()\n",
    "    model_random.fit(tf_idf_train, train_target)\n",
    "    print('Время подбора параметров %.2f секунд' %(time() - start))\n",
    "    \n",
    "    # подсчет метрик\n",
    "    f1 = model_random.best_score_\n",
    "    f1_on_train = f1_score(train_target, model_random.predict(tf_idf_train))\n",
    "    \n",
    "    print('Лучшие параметры:', model_random.best_params_)\n",
    "    print('F1 обученной модели:', f1)\n",
    "    print('F1 на тренировочной выборке:', f1_on_train)\n",
    "\n",
    "    # заполним все таблицы    \n",
    "    all_models.append(model_random)\n",
    "    row = []\n",
    "    row.extend([model, f1, f1_on_train])\n",
    "    analisys.loc[len(analisys.index)] = row\n",
    "    \n",
    "    return model_random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section2.1'></a>\n",
    "**LogisticRegression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "[CV] END ..................class_weight=balanced, penalty=l1; total time=   0.0s\n",
      "[CV] END ..................class_weight=balanced, penalty=l1; total time=   0.0s\n",
      "[CV] END ..................class_weight=balanced, penalty=l1; total time=   0.0s\n",
      "[CV] END ..................class_weight=balanced, penalty=l1; total time=   0.0s\n",
      "[CV] END ..................class_weight=balanced, penalty=l2; total time=  45.4s\n",
      "[CV] END ..................class_weight=balanced, penalty=l2; total time=  39.2s\n",
      "[CV] END ..................class_weight=balanced, penalty=l2; total time=  57.3s\n",
      "[CV] END ..................class_weight=balanced, penalty=l2; total time=  57.8s\n",
      "[CV] END ..........class_weight=balanced, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END ..........class_weight=balanced, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END ..........class_weight=balanced, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END ..........class_weight=balanced, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END ................class_weight=balanced, penalty=none; total time= 7.3min\n",
      "[CV] END ................class_weight=balanced, penalty=none; total time= 7.4min\n",
      "[CV] END ................class_weight=balanced, penalty=none; total time= 7.1min\n",
      "[CV] END ................class_weight=balanced, penalty=none; total time= 7.2min\n",
      "[CV] END ......................class_weight=none, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................class_weight=none, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................class_weight=none, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................class_weight=none, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................class_weight=none, penalty=l2; total time=  39.0s\n",
      "[CV] END ......................class_weight=none, penalty=l2; total time=  30.2s\n",
      "[CV] END ......................class_weight=none, penalty=l2; total time=  39.2s\n",
      "[CV] END ......................class_weight=none, penalty=l2; total time=  37.7s\n",
      "[CV] END ..............class_weight=none, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END ..............class_weight=none, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END ..............class_weight=none, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END ..............class_weight=none, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END ....................class_weight=none, penalty=none; total time= 7.2min\n",
      "[CV] END ....................class_weight=none, penalty=none; total time= 7.2min\n",
      "[CV] END ....................class_weight=none, penalty=none; total time= 7.6min\n",
      "[CV] END ....................class_weight=none, penalty=none; total time= 7.5min\n",
      "Время подбора параметров 3930.00 секунд\n",
      "Лучшие параметры: {'penalty': 'l2', 'class_weight': 'balanced'}\n",
      "F1 обученной модели: 0.74488439459101\n",
      "F1 на тренировочной выборке: 0.8316810574565612\n"
     ]
    }
   ],
   "source": [
    "# задаём рандомные параметры\n",
    "ran_lr = {\"penalty\": ['l1', 'l2', 'elasticnet', 'none'],\n",
    "    \"class_weight\": ['balanced', 'none'],}\n",
    "\n",
    "logr  = LogisticRegression(max_iter = 1000)\n",
    "\n",
    "# обучение и сохранение значений\n",
    "lr_random = train_model(logr , ran_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section2.2'></a>\n",
    "**DecisionTreeClassifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 10 candidates, totalling 40 fits\n",
      "[CV] END .......................................max_depth=48; total time=  25.5s\n",
      "[CV] END .......................................max_depth=48; total time=  25.6s\n",
      "[CV] END .......................................max_depth=48; total time=  25.5s\n",
      "[CV] END .......................................max_depth=48; total time=  25.2s\n",
      "[CV] END .......................................max_depth=54; total time=  28.6s\n",
      "[CV] END .......................................max_depth=54; total time=  27.5s\n",
      "[CV] END .......................................max_depth=54; total time=  27.9s\n",
      "[CV] END .......................................max_depth=54; total time=  27.4s\n",
      "[CV] END .......................................max_depth=50; total time=  26.3s\n",
      "[CV] END .......................................max_depth=50; total time=  26.1s\n",
      "[CV] END .......................................max_depth=50; total time=  25.8s\n",
      "[CV] END .......................................max_depth=50; total time=  25.5s\n",
      "[CV] END .......................................max_depth=45; total time=  23.8s\n",
      "[CV] END .......................................max_depth=45; total time=  24.0s\n",
      "[CV] END .......................................max_depth=45; total time=  23.9s\n",
      "[CV] END .......................................max_depth=45; total time=  23.5s\n",
      "[CV] END .......................................max_depth=46; total time=  24.6s\n",
      "[CV] END .......................................max_depth=46; total time=  25.1s\n",
      "[CV] END .......................................max_depth=46; total time=  24.4s\n",
      "[CV] END .......................................max_depth=46; total time=  24.2s\n",
      "[CV] END .......................................max_depth=51; total time=  26.3s\n",
      "[CV] END .......................................max_depth=51; total time=  27.0s\n",
      "[CV] END .......................................max_depth=51; total time=  26.9s\n",
      "[CV] END .......................................max_depth=51; total time=  26.3s\n",
      "[CV] END .......................................max_depth=55; total time=  27.4s\n",
      "[CV] END .......................................max_depth=55; total time=  28.4s\n",
      "[CV] END .......................................max_depth=55; total time=  28.0s\n",
      "[CV] END .......................................max_depth=55; total time=  27.3s\n",
      "[CV] END .......................................max_depth=47; total time=  24.7s\n",
      "[CV] END .......................................max_depth=47; total time=  24.9s\n",
      "[CV] END .......................................max_depth=47; total time=  24.9s\n",
      "[CV] END .......................................max_depth=47; total time=  24.4s\n",
      "[CV] END .......................................max_depth=49; total time=  25.9s\n",
      "[CV] END .......................................max_depth=49; total time=  25.5s\n",
      "[CV] END .......................................max_depth=49; total time=  25.7s\n",
      "[CV] END .......................................max_depth=49; total time=  25.5s\n",
      "[CV] END .......................................max_depth=53; total time=  27.2s\n",
      "[CV] END .......................................max_depth=53; total time=  27.6s\n",
      "[CV] END .......................................max_depth=53; total time=  27.3s\n",
      "[CV] END .......................................max_depth=53; total time=  27.0s\n",
      "Время подбора параметров 1069.44 секунд\n",
      "Лучшие параметры: {'max_depth': 55}\n",
      "F1 обученной модели: 0.7084743897981118\n",
      "F1 на тренировочной выборке: 0.8233362310441418\n"
     ]
    }
   ],
   "source": [
    "ran_grid_tree = {\"max_depth\": list(range(45, 56))}\n",
    "\n",
    "dtr = DecisionTreeClassifier()\n",
    "\n",
    "dtr_random = train_model(dtr, ran_grid_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section2.3'></a>\n",
    "**RandomForestClassifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 4 candidates, totalling 16 fits\n",
      "[CV] END .....................max_depth=300, n_estimators=12; total time= 1.0min\n",
      "[CV] END .....................max_depth=300, n_estimators=12; total time= 1.0min\n",
      "[CV] END .....................max_depth=300, n_estimators=12; total time= 1.0min\n",
      "[CV] END .....................max_depth=300, n_estimators=12; total time= 1.0min\n",
      "[CV] END .....................max_depth=300, n_estimators=14; total time= 1.2min\n",
      "[CV] END .....................max_depth=300, n_estimators=14; total time= 1.2min\n",
      "[CV] END .....................max_depth=300, n_estimators=14; total time= 1.1min\n",
      "[CV] END .....................max_depth=300, n_estimators=14; total time= 1.1min\n",
      "[CV] END .....................max_depth=310, n_estimators=12; total time= 1.0min\n",
      "[CV] END .....................max_depth=310, n_estimators=12; total time= 1.0min\n",
      "[CV] END .....................max_depth=310, n_estimators=12; total time= 1.0min\n",
      "[CV] END .....................max_depth=310, n_estimators=12; total time=  59.6s\n",
      "[CV] END .....................max_depth=310, n_estimators=14; total time= 1.2min\n",
      "[CV] END .....................max_depth=310, n_estimators=14; total time= 1.2min\n",
      "[CV] END .....................max_depth=310, n_estimators=14; total time= 1.1min\n",
      "[CV] END .....................max_depth=310, n_estimators=14; total time= 1.2min\n",
      "Время подбора параметров 1085.94 секунд\n",
      "Лучшие параметры: {'n_estimators': 14, 'max_depth': 310}\n",
      "F1 обученной модели: 0.6277370474621671\n",
      "F1 на тренировочной выборке: 0.9162130811100204\n"
     ]
    }
   ],
   "source": [
    "ran_grid_forest = {'max_depth': [300, 310],\n",
    "    'n_estimators': [12, 14],}\n",
    "\n",
    "rfc = RandomForestClassifier(n_jobs=-1)\n",
    "\n",
    "rfc_random = train_model(rfc, ran_grid_forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section2.4'></a>\n",
    "**LGBMClassifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 4 candidates, totalling 16 fits\n",
      "[CV] END ....................learning_rate=0.1, max_depth=15; total time= 2.2min\n",
      "[CV] END ....................learning_rate=0.1, max_depth=15; total time= 2.2min\n",
      "[CV] END ....................learning_rate=0.1, max_depth=15; total time= 2.3min\n",
      "[CV] END ....................learning_rate=0.1, max_depth=15; total time= 2.3min\n",
      "[CV] END ....................learning_rate=0.1, max_depth=25; total time= 2.4min\n",
      "[CV] END ....................learning_rate=0.1, max_depth=25; total time= 2.5min\n",
      "[CV] END ....................learning_rate=0.1, max_depth=25; total time= 2.5min\n",
      "[CV] END ....................learning_rate=0.1, max_depth=25; total time= 2.4min\n",
      "[CV] END ....................learning_rate=0.3, max_depth=15; total time= 2.1min\n",
      "[CV] END ....................learning_rate=0.3, max_depth=15; total time= 2.1min\n",
      "[CV] END ....................learning_rate=0.3, max_depth=15; total time= 2.0min\n",
      "[CV] END ....................learning_rate=0.3, max_depth=15; total time= 2.0min\n",
      "[CV] END ....................learning_rate=0.3, max_depth=25; total time= 2.5min\n",
      "[CV] END ....................learning_rate=0.3, max_depth=25; total time= 2.4min\n",
      "[CV] END ....................learning_rate=0.3, max_depth=25; total time= 2.4min\n",
      "[CV] END ....................learning_rate=0.3, max_depth=25; total time= 2.3min\n",
      "Время подбора параметров 2390.39 секунд\n",
      "Лучшие параметры: {'max_depth': 25, 'learning_rate': 0.3}\n",
      "F1 обученной модели: 0.7650325271869963\n",
      "F1 на тренировочной выборке: 0.8568440200090951\n"
     ]
    }
   ],
   "source": [
    "rand_lgbm_param = {\n",
    "    'max_depth': [15, 25],\n",
    "    'learning_rate': [0.1, 0.3]\n",
    "}\n",
    "\n",
    "gbm = lgb.LGBMClassifier(\n",
    "    boosting_type='gbdt',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "gbm_random= train_model(gbm, rand_lgbm_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section2.5'></a>\n",
    "**XGBClassifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "[02:05:47] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END .....................learning_rate=0.5, max_depth=6; total time= 2.6min\n",
      "[02:08:24] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END .....................learning_rate=0.5, max_depth=6; total time= 2.6min\n",
      "[02:11:01] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END .....................learning_rate=0.5, max_depth=6; total time= 2.7min\n",
      "[02:13:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END .....................learning_rate=0.5, max_depth=6; total time= 2.6min\n",
      "[02:16:18] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END .....................learning_rate=0.5, max_depth=7; total time= 3.1min\n",
      "[02:19:23] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END .....................learning_rate=0.5, max_depth=7; total time= 3.0min\n",
      "[02:22:25] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END .....................learning_rate=0.5, max_depth=7; total time= 3.1min\n",
      "[02:25:30] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END .....................learning_rate=0.5, max_depth=7; total time= 3.1min\n",
      "[02:28:37] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END .....................learning_rate=0.5, max_depth=8; total time= 3.4min\n",
      "[02:32:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END .....................learning_rate=0.5, max_depth=8; total time= 3.4min\n",
      "[02:35:25] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END .....................learning_rate=0.5, max_depth=8; total time= 3.2min\n",
      "[02:38:37] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END .....................learning_rate=0.5, max_depth=8; total time= 3.3min\n",
      "[02:41:53] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END .....................learning_rate=0.5, max_depth=9; total time= 3.6min\n",
      "[02:45:29] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END .....................learning_rate=0.5, max_depth=9; total time= 3.6min\n",
      "[02:49:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END .....................learning_rate=0.5, max_depth=9; total time= 3.6min\n",
      "[02:52:39] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END .....................learning_rate=0.5, max_depth=9; total time= 3.6min\n",
      "[02:56:12] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END .....................learning_rate=1.0, max_depth=6; total time= 2.4min\n",
      "[02:58:35] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END .....................learning_rate=1.0, max_depth=6; total time= 2.5min\n",
      "[03:01:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END .....................learning_rate=1.0, max_depth=6; total time= 2.6min\n",
      "[03:03:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END .....................learning_rate=1.0, max_depth=6; total time= 2.4min\n",
      "[03:06:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END .....................learning_rate=1.0, max_depth=7; total time= 2.8min\n",
      "[03:08:49] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END .....................learning_rate=1.0, max_depth=7; total time= 2.8min\n",
      "[03:11:35] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END .....................learning_rate=1.0, max_depth=7; total time= 2.7min\n",
      "[03:14:19] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END .....................learning_rate=1.0, max_depth=7; total time= 2.9min\n",
      "[03:17:13] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END .....................learning_rate=1.0, max_depth=8; total time= 4.0min\n",
      "[03:21:13] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END .....................learning_rate=1.0, max_depth=8; total time= 4.6min\n",
      "[03:25:51] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END .....................learning_rate=1.0, max_depth=8; total time= 4.7min\n",
      "[03:30:30] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END .....................learning_rate=1.0, max_depth=8; total time= 4.6min\n",
      "[03:35:10] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END .....................learning_rate=1.0, max_depth=9; total time= 5.3min\n",
      "[03:40:25] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END .....................learning_rate=1.0, max_depth=9; total time= 5.1min\n",
      "[03:45:32] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END .....................learning_rate=1.0, max_depth=9; total time= 5.2min\n",
      "[03:50:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END .....................learning_rate=1.0, max_depth=9; total time= 5.1min\n",
      "[03:55:50] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Время подбора параметров 7009.53 секунд\n",
      "Лучшие параметры: {'max_depth': 9, 'learning_rate': 0.5}\n",
      "F1 обученной модели: 0.7516591506647347\n",
      "F1 на тренировочной выборке: 0.8563949483352469\n"
     ]
    }
   ],
   "source": [
    "rand_xgb_param = {\n",
    "    'max_depth': [6, 7, 8, 9],\n",
    "    'learning_rate': [0.5, 1.0]\n",
    "}\n",
    "\n",
    "xb = xgb.XGBClassifier(booster = 'gbtree', \n",
    "                      use_rmm = True,\n",
    "                      n_jobs = -1)\n",
    "\n",
    "xb_random = train_model(xb, rand_xgb_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод:**\n",
    "\n",
    "- Обучены модели LogisticRegression, DecisionTreeClassifier, RandomForestClassifier, LGBMClassifier, XGBClassifier.\n",
    "- Гиперпараметры найдены."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Соберем в таблицу результаты обученных моделей и посмотрим результат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>F1_model</th>\n",
       "      <th>F1_on_train</th>\n",
       "      <th>names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression(max_iter=1000)</td>\n",
       "      <td>0.744884</td>\n",
       "      <td>0.831681</td>\n",
       "      <td>LogisticRegression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>0.708474</td>\n",
       "      <td>0.823336</td>\n",
       "      <td>DecisionTree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestClassifier(n_jobs=-1)</td>\n",
       "      <td>0.627737</td>\n",
       "      <td>0.916213</td>\n",
       "      <td>RandomForest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LGBMClassifier()</td>\n",
       "      <td>0.765033</td>\n",
       "      <td>0.856844</td>\n",
       "      <td>LightGBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBClassifier(base_score=None, booster='gbtree...</td>\n",
       "      <td>0.751659</td>\n",
       "      <td>0.856395</td>\n",
       "      <td>XGBoost</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               model  F1_model  F1_on_train  \\\n",
       "0                  LogisticRegression(max_iter=1000)  0.744884     0.831681   \n",
       "1                           DecisionTreeClassifier()  0.708474     0.823336   \n",
       "2                  RandomForestClassifier(n_jobs=-1)  0.627737     0.916213   \n",
       "3                                   LGBMClassifier()  0.765033     0.856844   \n",
       "4  XGBClassifier(base_score=None, booster='gbtree...  0.751659     0.856395   \n",
       "\n",
       "                names  \n",
       "0  LogisticRegression  \n",
       "1        DecisionTree  \n",
       "2        RandomForest  \n",
       "3            LightGBM  \n",
       "4             XGBoost  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_names = pd.DataFrame({'names':[ 'LogisticRegression', 'DecisionTree', 'RandomForest', 'LightGBM', 'XGBoost']})\n",
    "analisys = pd.concat([analisys, all_names], axis=1, join='inner')\n",
    "display(analisys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Исходя из полученных метрик качества моделей, лучшая модель на RandomizedSearchCV - LightGBM c параметрами max_depth: 25, learning_rate: 0.3. На тренировочной выборке, лучшую метрику показывает модель Случайного леса, но и худшую на подборе параметров, то есть модель переобучена и не показывает нужных метрик."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим качество лучшей модели на тестовой выборке, которая уже обучена."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 : 0.7680534298038124\n"
     ]
    }
   ],
   "source": [
    "predicted = gbm_random.predict(tf_idf_test)\n",
    "print('F1 :', f1_score(test_target, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод:**\n",
    "\n",
    "Необходимые метрики достигнуты, модель LightGBM, обученная через RandomizedSearchCV, предсказывает с необходимой метрикой: F1 > 0.75."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Общий вывод:**\n",
    "- Данные загрежены, обработаны, проведене токенизация и лемматизация.\n",
    "- Определены тестовая и тренеровачная выборки.\n",
    "- TF-IDF подсчитано.\n",
    "- Обучены модели LogisticRegression, DecisionTreeClassifier, RandomForestClassifier, LGBMClassifier, XGBClassifier, и найдены сответствующие гиперпараметры.\n",
    "- Модель LightGBM показала значение метрики качества F1 не меньше 0.75 по условию и равно 0.7680 соответственно."
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 1849,
    "start_time": "2022-09-15T22:39:33.645Z"
   },
   {
    "duration": 3078,
    "start_time": "2022-09-15T22:40:26.226Z"
   },
   {
    "duration": 747,
    "start_time": "2022-09-15T22:40:42.733Z"
   },
   {
    "duration": 333,
    "start_time": "2022-09-15T22:41:56.217Z"
   },
   {
    "duration": 4,
    "start_time": "2022-09-15T22:43:25.452Z"
   },
   {
    "duration": 11,
    "start_time": "2022-09-15T22:45:07.416Z"
   },
   {
    "duration": 6,
    "start_time": "2022-09-15T22:45:12.185Z"
   },
   {
    "duration": 31,
    "start_time": "2022-09-15T22:46:44.560Z"
   },
   {
    "duration": 3,
    "start_time": "2022-09-15T22:50:10.772Z"
   },
   {
    "duration": 78,
    "start_time": "2022-09-15T22:54:09.744Z"
   },
   {
    "duration": 3,
    "start_time": "2022-09-15T22:54:15.400Z"
   },
   {
    "duration": 4,
    "start_time": "2022-09-15T22:55:32.079Z"
   },
   {
    "duration": 78051,
    "start_time": "2022-09-15T22:56:01.123Z"
   },
   {
    "duration": 6,
    "start_time": "2022-09-15T23:02:07.751Z"
   },
   {
    "duration": 7,
    "start_time": "2022-09-15T23:04:18.366Z"
   },
   {
    "duration": 96,
    "start_time": "2022-09-15T23:04:57.762Z"
   },
   {
    "duration": 5,
    "start_time": "2022-09-15T23:05:23.758Z"
   },
   {
    "duration": 6515,
    "start_time": "2022-09-15T23:06:58.382Z"
   },
   {
    "duration": 6307,
    "start_time": "2022-09-15T23:07:49.314Z"
   },
   {
    "duration": 6,
    "start_time": "2022-09-15T23:25:12.284Z"
   },
   {
    "duration": 88638,
    "start_time": "2022-09-15T23:27:56.708Z"
   },
   {
    "duration": 6,
    "start_time": "2022-09-15T23:29:35.832Z"
   },
   {
    "duration": 5,
    "start_time": "2022-09-15T23:29:39.200Z"
   },
   {
    "duration": 5,
    "start_time": "2022-09-15T23:29:41.984Z"
   },
   {
    "duration": 80953,
    "start_time": "2022-09-15T23:29:48.256Z"
   },
   {
    "duration": 1787,
    "start_time": "2022-09-15T23:39:04.995Z"
   },
   {
    "duration": 195,
    "start_time": "2022-09-15T23:39:06.784Z"
   },
   {
    "duration": 814,
    "start_time": "2022-09-15T23:39:06.980Z"
   },
   {
    "duration": 12,
    "start_time": "2022-09-15T23:39:07.797Z"
   },
   {
    "duration": 39,
    "start_time": "2022-09-15T23:39:07.810Z"
   },
   {
    "duration": 7,
    "start_time": "2022-09-15T23:39:07.851Z"
   },
   {
    "duration": 7,
    "start_time": "2022-09-15T23:39:07.860Z"
   },
   {
    "duration": 24,
    "start_time": "2022-09-15T23:39:07.869Z"
   },
   {
    "duration": 77101,
    "start_time": "2022-09-15T23:39:07.894Z"
   },
   {
    "duration": 116,
    "start_time": "2022-09-15T23:40:24.999Z"
   },
   {
    "duration": 7,
    "start_time": "2022-09-15T23:40:25.117Z"
   },
   {
    "duration": 6252,
    "start_time": "2022-09-15T23:40:25.125Z"
   },
   {
    "duration": 10,
    "start_time": "2022-09-15T23:40:31.379Z"
   },
   {
    "duration": 3930245,
    "start_time": "2022-09-15T23:40:31.391Z"
   },
   {
    "duration": 1069621,
    "start_time": "2022-09-16T00:46:01.638Z"
   },
   {
    "duration": 1087453,
    "start_time": "2022-09-16T01:03:51.260Z"
   },
   {
    "duration": 2400439,
    "start_time": "2022-09-16T01:21:58.714Z"
   },
   {
    "duration": 0,
    "start_time": "2022-09-16T02:05:38.652Z"
   },
   {
    "duration": 0,
    "start_time": "2022-09-16T02:05:38.653Z"
   },
   {
    "duration": 10,
    "start_time": "2022-09-16T02:05:42.777Z"
   },
   {
    "duration": 7010564,
    "start_time": "2022-09-16T02:05:45.861Z"
   },
   {
    "duration": 100,
    "start_time": "2022-09-16T04:02:36.427Z"
   },
   {
    "duration": 15,
    "start_time": "2022-09-16T08:54:00.178Z"
   },
   {
    "duration": 18,
    "start_time": "2022-09-16T09:05:45.924Z"
   },
   {
    "duration": 42,
    "start_time": "2022-09-16T09:05:46.506Z"
   },
   {
    "duration": 515,
    "start_time": "2022-09-16T09:05:47.036Z"
   },
   {
    "duration": 2976,
    "start_time": "2022-09-16T09:05:48.053Z"
   },
   {
    "duration": 358,
    "start_time": "2022-09-16T09:05:52.956Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.389px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
